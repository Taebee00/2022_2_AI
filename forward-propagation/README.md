## 순전파 계산

![image](https://github.com/Taebee00/2022_2_AI/assets/104549849/72fbb02f-b694-43ac-b270-4699b470e9b0)

- 입력과 출력
    
    노드에 들어오는 모든 입력값을 각각의 가중치와 곱한 후 그 각각의 값의 합을 구하고, 거기에 활성화 함수를 적용하여 출력
    
- Layer 2의 1번 노드에 들어가는 입력값:
    
    $1.0 * 0.9+0.5*0.3=1.05$
    
- Layer 2의 1번 노드의 출력값(시그모이드 함수 ($1/1+e^{-x}$)적용:
    
    $1/1+e^{-1.05}=0.7408$
    
- 따라서 N번 Layer의 출력값은 N-1번 Layer의 출력값 행렬과 N-1~N 가중치 행렬의 행렬곱에 시그모이드 함수를 적용한 값임

- `행렬`로 순전파 계산 표현하기
    - $X = W*I$
        - $W$: 가중치 행렬, $I$: 입력값 행렬, $X$: 다음 계층의 입력 행렬
        - 행렬을 통해 복잡한 계산을 간단한 형태로 표현할 수 있으며 행렬 기반의 연산으로 빠르게 컴퓨터가 처리할 수 있다.
    - $O = sigmoid(X)$
        - $O:$ 노드의 출력값
        - 입력값과 가중치의 곱의 합에 시그모이드를 취한 것이 최종 노드의 출력값
- 순전파 계산을 통해 (최종 노드)출력 노드의 출력값을 구할 수 있고, 그렇다면 목표값에서 출력값을 뺀 오차값을 구할 수 있음. 출력의 오차값을 줄이기 위해서는 입력값은 정해져 있고, 목표값도 정해져 있으므로 Weight(가중치)값을 조정해야 함

- 입력과 출력
    
    노드에 들어오는 모든 입력값을 각각의 가중치와 곱한 후 그 각각의 값의 합을 구하고, 거기에 활성화 함수를 적용하여 출력
    
- Layer 2의 1번 노드에 들어가는 입력값:
    
    $1.0 * 0.9+0.5*0.3=1.05$
    
- Layer 2의 1번 노드의 출력값(시그모이드 함수 ($1/1+e^{-x}$)적용:
    
    $1/1+e^{-1.05}=0.7408$
    
- 따라서 N번 Layer의 출력값은 N-1번 Layer의 출력값 행렬과 N-1~N 가중치 행렬의 행렬곱에 시그모이드 함수를 적용한 값임

- `행렬`로 순전파 계산 표현하기
    - $X = W*I$
        - $W$: 가중치 행렬, $I$: 입력값 행렬, $X$: 다음 계층의 입력 행렬
        - 행렬을 통해 복잡한 계산을 간단한 형태로 표현할 수 있으며 행렬 기반의 연산으로 빠르게 컴퓨터가 처리할 수 있다.
    - $O = sigmoid(X)$
        - $O:$ 노드의 출력값
        - 입력값과 가중치의 곱의 합에 시그모이드를 취한 것이 최종 노드의 출력값
- 순전파 계산을 통해 (최종 노드)출력 노드의 출력값을 구할 수 있고, 그렇다면 목표값에서 출력값을 뺀 오차값을 구할 수 있음. 출력의 오차값을 줄이기 위해서는 입력값은 정해져 있고, 목표값도 정해져 있으므로 Weight(가중치)값을 조정해야 함

## 출력
### 2x2_neural_network.c
![image](https://github.com/Taebee00/2022_2_AI/assets/104549849/7c898a26-19e6-4f68-8e05-cf158182eaec)

### 3x3_neural_network.c
![image](https://github.com/Taebee00/2022_2_AI/assets/104549849/eb808749-b18c-4e81-9354-83f19c84962f)

### 3x3_random_neural_network.c
![image](https://github.com/Taebee00/2022_2_AI/assets/104549849/3bd62c16-90ea-476e-90c2-3cd8516813ce)

